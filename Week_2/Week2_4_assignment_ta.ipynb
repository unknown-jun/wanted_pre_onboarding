{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "592U6lXs3d2t"
      },
      "source": [
        "# Week2_4 Assignment\n",
        "\n",
        "## [BASIC](#Basic) \n",
        "- 커스텀 모듈(`helper.py`)에서 **클래스와 함수를 임포트**할 수 있다.\n",
        "- **autograd**의 개념 복습\n",
        "\n",
        "\n",
        "## [CHALLENGE](#Challenge)\n",
        "- train() 함수에 **epoch, scheduler, grad_clipping**을 추가할 수 있다.\n",
        "- **validate() 함수를 구현**할 수 있다.\n",
        "\n",
        "\n",
        "## [ADVANCED](#Advanced)\n",
        "- train() 함수를 사용해 데이터를 **4 epoch 학습**할 수 있다. \n",
        "- **predict 함수를 구현**할 수 있다. \n",
        "- **evaluation metric 구현**할 수 있다. \n",
        "    - accuracy\n",
        "\n",
        "\n",
        "\n",
        "### Reference\n",
        "- [Pytorch Autograd Explain official document](https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-02T04:01:47.370876Z",
          "start_time": "2022-02-02T04:01:46.520392Z"
        },
        "id": "KSX-wQA1RD1h"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import pandas as pd\n",
        "import numpy as np \n",
        "import torch\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-02T04:01:47.375658Z",
          "start_time": "2022-02-02T04:01:47.372242Z"
        },
        "id": "MH7RJjtZXOHf"
      },
      "outputs": [],
      "source": [
        "# set seed\n",
        "seed = 7777\n",
        "random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-31T13:07:00.849353Z",
          "start_time": "2022-01-31T13:06:56.187962Z"
        },
        "collapsed": true,
        "id": "62plMahMWr0U",
        "outputId": "5729f4a0-c6a8-4b8d-be33-c04726b2ceca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.17.0-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 9.8 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 48.4 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 44.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting tokenizers!=0.11.3,>=0.11.1\n",
            "  Downloading tokenizers-0.11.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.5 MB 35.7 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 5.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.63.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.4.0 pyyaml-6.0 sacremoses-0.0.47 tokenizers-0.11.6 transformers-4.17.0\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6WagJcj-Ud4L",
        "outputId": "ba25923a-0d16-4e16-a16a-53943eed724b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qnETqIqdVApF"
      },
      "outputs": [],
      "source": [
        "# helper.py 모듈 경로를 입력\n",
        "sys.path.append('/content/drive/MyDrive/NLP강의/jupyter_notebook/week2/assignments')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-02T04:01:49.735578Z",
          "start_time": "2022-02-02T04:01:49.475969Z"
        },
        "id": "N84mZeYMUFxJ"
      },
      "outputs": [],
      "source": [
        "# helper 모듈을 import하면 이전에 구현했던 다양한 함수 및 클래스를 사용할 수 있음\n",
        "from helper import *\n",
        "from torch.utils.data import RandomSampler, SequentialSampler, random_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-02T04:01:49.771743Z",
          "start_time": "2022-02-02T04:01:49.736866Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oR5EWmh5UFxK",
        "outputId": "1f6b3671-a85f-4ee8-f45f-328a18913eae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# available GPUs : 1\n",
            "GPU name : Tesla T4\n",
            "device: cuda\n"
          ]
        }
      ],
      "source": [
        "# device\n",
        "device = set_device()\n",
        "print(f\"device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "moAKpaWPaMel"
      },
      "source": [
        "## Basic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "esJeUdYCaMem"
      },
      "source": [
        "### 모듈에서 클래스와 함수를 임포트해 다음을 구현\n",
        "- train_dataset, train_dataloader\n",
        "- valid_dataset, valid_dataloader\n",
        "- test_dataset, test_dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-02T04:01:53.037044Z",
          "start_time": "2022-02-02T04:01:52.707669Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KVo5dPnmUFxK",
        "outputId": "871b1731-d37d-450b-9146-dc4e5acbe7f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-03-05 18:05:43--  https://raw.githubusercontent.com/ChristinaROK/PreOnboarding_AI_assets/e56006adfac42f8a2975db0ebbe60eacbe1c6b11/data/sample_df.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 971625 (949K) [text/plain]\n",
            "Saving to: ‘sample_df.csv’\n",
            "\n",
            "sample_df.csv       100%[===================>] 948.85K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2022-03-05 18:05:43 (30.6 MB/s) - ‘sample_df.csv’ saved [971625/971625]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# train dataframe 다운로드\n",
        "!wget https://raw.githubusercontent.com/ChristinaROK/PreOnboarding_AI_assets/e56006adfac42f8a2975db0ebbe60eacbe1c6b11/data/sample_df.csv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test dataframe 다운로드\n",
        "!wget https://raw.githubusercontent.com/ChristinaROK/PreOnboarding_AI_assets/main/data/sample_df_test.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJMGVwnTQlwa",
        "outputId": "70737341-140d-4a4c-86b6-357294a1b173"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-03-05 18:05:51--  https://raw.githubusercontent.com/ChristinaROK/PreOnboarding_AI_assets/main/data/sample_df_test.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 101383 (99K) [text/plain]\n",
            "Saving to: ‘sample_df_test.csv’\n",
            "\n",
            "\rsample_df_test.csv    0%[                    ]       0  --.-KB/s               \rsample_df_test.csv  100%[===================>]  99.01K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2022-03-05 18:05:51 (7.76 MB/s) - ‘sample_df_test.csv’ saved [101383/101383]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 & 평가 데이터셋 로드\n",
        "# 학습 및 평가 샘플 데이터 개수는 각각 10,000개, 1,000개\n",
        "\n",
        "df_train = pd.read_csv('sample_df.csv')\n",
        "df_test = pd.read_csv('sample_df_test.csv')\n",
        "\n",
        "print(f\"train shape : {df_train.shape}\")\n",
        "print(f\"test shape : {df_test.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-0PnHWzQm4i",
        "outputId": "4fcbe813-20ca-4c22-d09b-ff6848aefe9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train shape : (10000, 3)\n",
            "test shape : (1000, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-02T04:01:53.085720Z",
          "start_time": "2022-02-02T04:01:53.081413Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ql82Ew2VUFxM",
        "outputId": "7c296d50-39e7-4cd7-9529-aa09c0cc1576"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Dataset len: 10000\n",
            "Train Dataset 1st element: ('나 이거 더빙을 누가하는지 모르고 봤는데 왠지 더빙이 구리더라...더빙이 너무 별로였음.', 0)\n",
            "Test Dataset len: 1000\n",
            "Test Dataset 1st element: ('신용문객잔 보고 후속편인줄 알고 봤더만 완전 개판이네 18.. 이련결 그냥 절에나 쳐 들어 가라.. 회오리에서 싸우는 신 참 가관이더라 .. 서극도 완전 쓰레기 감독이 다 됐구나.. 액션도 쓰레기고 배우들 연기도 참 가관이더라 18', 0)\n"
          ]
        }
      ],
      "source": [
        "# Dataset 구현\n",
        "train_dataset = CustomDataset(df_train.document.to_list(), df_train.label.to_list())\n",
        "test_dataset = CustomDataset(df_test.document.to_list(), df_test.label.to_list())\n",
        "print(f\"Train Dataset len: {len(train_dataset)}\")\n",
        "print(f\"Train Dataset 1st element: {train_dataset[0]}\")\n",
        "\n",
        "print(f\"Test Dataset len: {len(test_dataset)}\")\n",
        "print(f\"Test Dataset 1st element: {test_dataset[0]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-02T04:01:53.152070Z",
          "start_time": "2022-02-02T04:01:53.145410Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7WUY6h8WUFxM",
        "outputId": "1adb6a46-50d0-4604-a611-ba4359aaac24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dataset len: 9000\n",
            "Valid dataset len: 1000\n"
          ]
        }
      ],
      "source": [
        "# Train Dataset을 학습과 검증 셋으로 분리\n",
        "n_train_sample = df_train.shape[0]\n",
        "\n",
        "n_train = int(n_train_sample*0.9)\n",
        "n_valid = n_train_sample - n_train #int(n_train_sample*0.1)\n",
        "train_dataset, valid_dataset = random_split(train_dataset, [n_train, n_valid])\n",
        "\n",
        "print(f\"Train dataset len: {len(train_dataset)}\")\n",
        "print(f\"Valid dataset len: {len(valid_dataset)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-02T04:01:53.268838Z",
          "start_time": "2022-02-02T04:01:53.263780Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5nc7SpTUFxM",
        "outputId": "f565b22f-ca3c-47a8-e87b-e85bebac8cb8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dataloader # steps: 282\n",
            "Valid dataloader # steps: 16\n",
            "Test dataloader # steps: 16\n"
          ]
        }
      ],
      "source": [
        "# DataLoader 구현\n",
        "train_batch_size = 32\n",
        "valid_batch_size = 64\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size = train_batch_size,\n",
        "    sampler = RandomSampler(train_dataset),\n",
        "    collate_fn = custom_collate_fn\n",
        ")\n",
        "\n",
        "valid_dataloader = DataLoader(\n",
        "    valid_dataset,\n",
        "    batch_size = valid_batch_size,\n",
        "    sampler = SequentialSampler(valid_dataset),\n",
        "    collate_fn = custom_collate_fn\n",
        ")\n",
        "\n",
        "test_dataloader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size = valid_batch_size,\n",
        "    sampler = SequentialSampler(test_dataset),\n",
        "    collate_fn = custom_collate_fn\n",
        ")\n",
        "print(f\"Train dataloader # steps: {len(train_dataloader)}\")\n",
        "print(f\"Valid dataloader # steps: {len(valid_dataloader)}\")\n",
        "print(f\"Test dataloader # steps: {len(test_dataloader)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kEgqvBIUFxN"
      },
      "source": [
        "### `auto_grad` 개념 복습\n",
        "- torch의 `auto_grad` 기능\n",
        "    - pytorch는 `requires_grad` 파리미터의 값이 True인 텐서에 한해서 미분값을 자동으로 계산한다.\n",
        "    - 미분값은 `loss.backward()` 가 호출될 때 자동으로 계산된다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-31T13:45:23.502936Z",
          "start_time": "2022-01-31T13:45:20.029987Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154,
          "referenced_widgets": [
            "0f906f35b2a04f2b9a98c5141b3500ed",
            "447f75968c8b478ab8fe3b2cb4fd6951",
            "ad20c09fa31c484687cb4008575649c8",
            "4849d465a2be4a95b03f5eaff782cc3f",
            "5b8538f4a1f94796a77fd8b6042e5ae9",
            "49f72347cc4d414e8a16ba04c4236029",
            "b23eaa8a9cba44328968f711af4a2943",
            "70a4249ac876489fbaa4286bfe73e883",
            "03c7552d696741fe992bce4b1bc9bb2a",
            "7a65ad8c877846e8a6f206eeb2754e31",
            "c4b1594093884ca5aabd96a386f81288",
            "1e604284d92542b181aca9f164404b89",
            "e2a022db622045c9b61a7ef909b0e5c3",
            "2442cef960ba45ddb52c03c00137a1b6",
            "f7522ff585f2423593e9f9d9fb75d588",
            "5bab9ea6663b4e8f8c028ca70d115064",
            "3250d59be7fd446a96bad425216de4f7",
            "1cabb1afb33546f4bdfda4116deeea4e",
            "5fc05b5d176f4a4bb8ad0aa528ddc1f0",
            "15e1406373834500885b5db22f89b1d2",
            "9b2b03353e2b48698b8952bc2e7abe65",
            "c1b421531cba4e9e961f1fe8cfe4428c"
          ]
        },
        "id": "oYjYpQ1DUFxN",
        "outputId": "76e12e12-cbdf-4123-cb31-42737d1fa5fe"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0f906f35b2a04f2b9a98c5141b3500ed",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/425 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1e604284d92542b181aca9f164404b89",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/424M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "# fine-tuning 모델 로드\n",
        "model_freeze = CustomClassifier(hidden_size=768, n_label=2, freeze_base=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BF9Pn0F-aMes"
      },
      "source": [
        "### `auto_grad` 개념 및 모델 구조 복습을 위해 다음 항목에 답해 보자\n",
        "- `bert.encoder.layer.0.attention.self.query.weight` 텐서의 gradient는 True인 상태인가?\n",
        "> 네\n",
        "- `classifier.0.weight` 텐서의 shape은? \n",
        "> (32,768)\n",
        "- `classifier.0.weight` 텐서는 freeze 상태인가 ? \n",
        "> 아니오\n",
        "- `classifier.0.weight` 텐서의 gradient 값은 무엇인가? \n",
        "> None "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-31T13:45:34.604914Z",
          "start_time": "2022-01-31T13:45:34.586711Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XxNFh8KZUFxN",
        "outputId": "46dc0a1d-e5d0-4163-834f-d34cd1a30b20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Param Name: bert.embeddings.word_embeddings.weight, Shape: torch.Size([32000, 768]), Grad: True\n",
            "Param Name: bert.embeddings.position_embeddings.weight, Shape: torch.Size([512, 768]), Grad: True\n",
            "Param Name: bert.embeddings.token_type_embeddings.weight, Shape: torch.Size([2, 768]), Grad: True\n",
            "Param Name: bert.embeddings.LayerNorm.weight, Shape: torch.Size([768]), Grad: True\n",
            "Param Name: bert.embeddings.LayerNorm.bias, Shape: torch.Size([768]), Grad: True\n",
            "Param Name: bert.encoder.layer.0.attention.self.query.weight, Shape: torch.Size([768, 768]), Grad: True\n",
            "Param Name: bert.encoder.layer.0.attention.self.query.bias, Shape: torch.Size([768]), Grad: True\n",
            "Param Name: bert.encoder.layer.0.attention.self.key.weight, Shape: torch.Size([768, 768]), Grad: True\n",
            "Param Name: bert.encoder.layer.0.attention.self.key.bias, Shape: torch.Size([768]), Grad: True\n",
            "Param Name: bert.encoder.layer.0.attention.self.value.weight, Shape: torch.Size([768, 768]), Grad: True\n",
            "Param Name: bert.encoder.layer.0.attention.self.value.bias, Shape: torch.Size([768]), Grad: True\n",
            "Param Name: bert.encoder.layer.0.attention.output.dense.weight, Shape: torch.Size([768, 768]), Grad: True\n",
            "Param Name: bert.encoder.layer.0.attention.output.dense.bias, Shape: torch.Size([768]), Grad: True\n",
            "Param Name: bert.encoder.layer.0.attention.output.LayerNorm.weight, Shape: torch.Size([768]), Grad: True\n",
            "Param Name: bert.encoder.layer.0.attention.output.LayerNorm.bias, Shape: torch.Size([768]), Grad: True\n",
            "Param Name: bert.encoder.layer.0.intermediate.dense.weight, Shape: torch.Size([3072, 768]), Grad: True\n",
            "Param Name: bert.encoder.layer.0.intermediate.dense.bias, Shape: torch.Size([3072]), Grad: True\n",
            "Param Name: bert.encoder.layer.0.output.dense.weight, Shape: torch.Size([768, 3072]), Grad: True\n",
            "Param Name: bert.encoder.layer.0.output.dense.bias, Shape: torch.Size([768]), Grad: True\n",
            "Param Name: bert.encoder.layer.0.output.LayerNorm.weight, Shape: torch.Size([768]), Grad: True\n",
            "Param Name: bert.encoder.layer.0.output.LayerNorm.bias, Shape: torch.Size([768]), Grad: True\n",
            "Param Name: bert.encoder.layer.1.attention.self.query.weight, Shape: torch.Size([768, 768]), Grad: True\n",
            "Param Name: bert.encoder.layer.1.attention.self.query.bias, Shape: torch.Size([768]), Grad: True\n",
            "Param Name: bert.encoder.layer.1.attention.self.key.weight, Shape: torch.Size([768, 768]), Grad: True\n",
            "Param Name: bert.encoder.layer.1.attention.self.key.bias, Shape: torch.Size([768]), Grad: True\n",
            "Param Name: bert.encoder.layer.1.attention.self.value.weight, Shape: torch.Size([768, 768]), Grad: True\n",
            "Param Name: bert.encoder.layer.1.attention.self.value.bias, Shape: torch.Size([768]), Grad: True\n",
            "Param Name: bert.encoder.layer.1.attention.output.dense.weight, Shape: torch.Size([768, 768]), Grad: True\n",
            "Param Name: bert.encoder.layer.1.attention.output.dense.bias, Shape: torch.Size([768]), Grad: True\n",
            "Param Name: bert.encoder.layer.1.attention.output.LayerNorm.weight, Shape: torch.Size([768]), Grad: True\n",
            "Param Name: bert.encoder.layer.1.attention.output.LayerNorm.bias, Shape: torch.Size([768]), Grad: True\n",
            "Param Name: bert.encoder.layer.1.intermediate.dense.weight, Shape: torch.Size([3072, 768]), Grad: True\n",
            "Param Name: bert.encoder.layer.1.intermediate.dense.bias, Shape: torch.Size([3072]), Grad: True\n",
            "Param Name: bert.encoder.layer.1.output.dense.weight, Shape: torch.Size([768, 3072]), Grad: True\n",
            "Param Name: bert.encoder.layer.1.output.dense.bias, Shape: torch.Size([768]), Grad: True\n",
            "Param Name: bert.encoder.layer.1.output.LayerNorm.weight, Shape: torch.Size([768]), Grad: True\n",
            "Param Name: bert.encoder.layer.1.output.LayerNorm.bias, Shape: torch.Size([768]), Grad: True\n",
            "Param Name: bert.encoder.layer.2.attention.self.query.weight, Shape: torch.Size([768, 768]), Grad: True\n",
            "Param Name: bert.encoder.layer.2.attention.self.query.bias, Shape: torch.Size([768]), Grad: True\n",
            "Param Name: bert.encoder.layer.2.attention.self.key.weight, Shape: torch.Size([768, 768]), Grad: True\n",
            "Param Name: bert.encoder.layer.2.attention.self.key.bias, Shape: torch.Size([768]), Grad: True\n",
            "Param Name: bert.encoder.layer.2.attention.self.value.weight, Shape: torch.Size([768, 768]), Grad: True\n",
            "Param Name: bert.encoder.layer.2.attention.self.value.bias, Shape: torch.Size([768]), Grad: True\n",
            "Param Name: bert.encoder.layer.2.attention.output.dense.weight, Shape: torch.Size([768, 768]), Grad: True\n",
            "Param Name: bert.encoder.layer.2.attention.output.dense.bias, Shape: torch.Size([768]), Grad: True\n",
            "Param Name: bert.encoder.layer.2.attention.output.LayerNorm.weight, Shape: torch.Size([768]), Grad: True\n",
            "Param Name: bert.encoder.layer.2.attention.output.LayerNorm.bias, Shape: torch.Size([768]), Grad: True\n",
            "Param Name: bert.encoder.layer.2.intermediate.dense.weight, Shape: torch.Size([3072, 768]), Grad: True\n",
            "Param Name: bert.encoder.layer.2.intermediate.dense.bias, Shape: torch.Size([3072]), Grad: True\n",
            "Param Name: bert.encoder.layer.2.output.dense.weight, Shape: torch.Size([768, 3072]), Grad: True\n",
            "Param Name: bert.encoder.layer.2.output.dense.bias, Shape: torch.Size([768]), Grad: True\n",
            "Param Name: bert.encoder.layer.2.output.LayerNorm.weight, Shape: torch.Size([768]), Grad: True\n",
            "Param Name: bert.encoder.layer.2.output.LayerNorm.bias, Shape: torch.Size([768]), Grad: True\n",
            "Param Name: bert.encoder.layer.3.attention.self.query.weight, Shape: torch.Size([768, 768]), Grad: True\n",
            "Param Name: bert.encoder.layer.3.attention.self.query.bias, Shape: torch.Size([768]), Grad: True\n",
            "Param Name: bert.encoder.layer.3.attention.self.key.weight, Shape: torch.Size([768, 768]), Grad: True\n",
            "Param Name: bert.encoder.layer.3.attention.self.key.bias, Shape: torch.Size([768]), Grad: True\n",
            "Param Name: bert.encoder.layer.3.attention.self.value.weight, Shape: torch.Size([768, 768]), Grad: True\n",
            "Param Name: bert.encoder.layer.3.attention.self.value.bias, Shape: torch.Size([768]), Grad: True\n",
            "Param Name: bert.encoder.layer.3.attention.output.dense.weight, Shape: torch.Size([768, 768]), Grad: True\n",
            "Param Name: bert.encoder.layer.3.attention.output.dense.bias, Shape: torch.Size([768]), Grad: True\n",
            "Param Name: bert.encoder.layer.3.attention.output.LayerNorm.weight, Shape: torch.Size([768]), Grad: True\n",
            "Param Name: bert.encoder.layer.3.attention.output.LayerNorm.bias, Shape: torch.Size([768]), Grad: True\n",
            "Param Name: bert.encoder.layer.3.intermediate.dense.weight, Shape: torch.Size([3072, 768]), Grad: True\n",
            "Param Name: bert.encoder.layer.3.intermediate.dense.bias, Shape: torch.Size([3072]), Grad: True\n",
            "Param Name: bert.encoder.layer.3.output.dense.weight, Shape: torch.Size([768, 3072]), Grad: True\n",
            "Param Name: bert.encoder.layer.3.output.dense.bias, Shape: torch.Size([768]), Grad: True\n",
            "Param Name: bert.encoder.layer.3.output.LayerNorm.weight, Shape: torch.Size([768]), Grad: True\n",
            "Param Name: bert.encoder.layer.3.output.LayerNorm.bias, Shape: torch.Size([768]), Grad: True\n",
            "Param Name: bert.encoder.layer.4.attention.self.query.weight, Shape: torch.Size([768, 768]), Grad: True\n",
            "Param Name: bert.encoder.layer.4.attention.self.query.bias, Shape: torch.Size([768]), Grad: True\n",
            "Param Name: bert.encoder.layer.4.attention.self.key.weight, Shape: torch.Size([768, 768]), Grad: True\n",
            "Param Name: bert.encoder.layer.4.attention.self.key.bias, Shape: torch.Size([768]), Grad: True\n",
            "Param Name: bert.encoder.layer.4.attention.self.value.weight, Shape: torch.Size([768, 768]), Grad: True\n",
            "Param Name: bert.encoder.layer.4.attention.self.value.bias, Shape: torch.Size([768]), Grad: True\n",
            "Param Name: bert.encoder.layer.4.attention.output.dense.weight, Shape: torch.Size([768, 768]), Grad: True\n",
            "Param Name: bert.encoder.layer.4.attention.output.dense.bias, Shape: torch.Size([768]), Grad: True\n",
            "Param Name: bert.encoder.layer.4.attention.output.LayerNorm.weight, Shape: torch.Size([768]), Grad: True\n",
            "Param Name: bert.encoder.layer.4.attention.output.LayerNorm.bias, Shape: torch.Size([768]), Grad: True\n",
            "Param Name: bert.encoder.layer.4.intermediate.dense.weight, Shape: torch.Size([3072, 768]), Grad: True\n",
            "Param Name: bert.encoder.layer.4.intermediate.dense.bias, Shape: torch.Size([3072]), Grad: True\n",
            "Param Name: bert.encoder.layer.4.output.dense.weight, Shape: torch.Size([768, 3072]), Grad: True\n",
            "Param Name: bert.encoder.layer.4.output.dense.bias, Shape: torch.Size([768]), Grad: True\n",
            "Param Name: bert.encoder.layer.4.output.LayerNorm.weight, Shape: torch.Size([768]), Grad: True\n",
            "Param Name: bert.encoder.layer.4.output.LayerNorm.bias, Shape: torch.Size([768]), Grad: True\n",
            "Param Name: bert.encoder.layer.5.attention.self.query.weight, Shape: torch.Size([768, 768]), Grad: True\n",
            "Param Name: bert.encoder.layer.5.attention.self.query.bias, Shape: torch.Size([768]), Grad: True\n",
            "Param Name: bert.encoder.layer.5.attention.self.key.weight, Shape: torch.Size([768, 768]), Grad: True\n",
            "Param Name: bert.encoder.layer.5.attention.self.key.bias, Shape: torch.Size([768]), Grad: True\n",
            "Param Name: bert.encoder.layer.5.attention.self.value.weight, Shape: torch.Size([768, 768]), Grad: True\n",
            "Param Name: bert.encoder.layer.5.attention.self.value.bias, Shape: torch.Size([768]), Grad: True\n",
            "Param Name: bert.encoder.layer.5.attention.output.dense.weight, Shape: torch.Size([768, 768]), Grad: True\n",
            "Param Name: bert.encoder.layer.5.attention.output.dense.bias, Shape: torch.Size([768]), Grad: True\n",
            "Param Name: bert.encoder.layer.5.attention.output.LayerNorm.weight, Shape: torch.Size([768]), Grad: True\n",
            "Param Name: bert.encoder.layer.5.attention.output.LayerNorm.bias, Shape: torch.Size([768]), Grad: True\n",
            "Param Name: bert.encoder.layer.5.intermediate.dense.weight, Shape: torch.Size([3072, 768]), Grad: True\n",
            "Param Name: bert.encoder.layer.5.intermediate.dense.bias, Shape: torch.Size([3072]), Grad: True\n",
            "Param Name: bert.encoder.layer.5.output.dense.weight, Shape: torch.Size([768, 3072]), Grad: True\n",
            "Param Name: bert.encoder.layer.5.output.dense.bias, Shape: torch.Size([768]), Grad: True\n",
            "Param Name: bert.encoder.layer.5.output.LayerNorm.weight, Shape: torch.Size([768]), Grad: True\n",
            "Param Name: bert.encoder.layer.5.output.LayerNorm.bias, Shape: torch.Size([768]), Grad: True\n",
            "Param Name: bert.encoder.layer.6.attention.self.query.weight, Shape: torch.Size([768, 768]), Grad: True\n",
            "Param Name: bert.encoder.layer.6.attention.self.query.bias, Shape: torch.Size([768]), Grad: True\n",
            "Param Name: bert.encoder.layer.6.attention.self.key.weight, Shape: torch.Size([768, 768]), Grad: True\n",
            "Param Name: bert.encoder.layer.6.attention.self.key.bias, Shape: torch.Size([768]), Grad: True\n",
            "Param Name: bert.encoder.layer.6.attention.self.value.weight, Shape: torch.Size([768, 768]), Grad: True\n",
            "Param Name: bert.encoder.layer.6.attention.self.value.bias, Shape: torch.Size([768]), Grad: True\n",
            "Param Name: bert.encoder.layer.6.attention.output.dense.weight, Shape: torch.Size([768, 768]), Grad: True\n",
            "Param Name: bert.encoder.layer.6.attention.output.dense.bias, Shape: torch.Size([768]), Grad: True\n",
            "Param Name: bert.encoder.layer.6.attention.output.LayerNorm.weight, Shape: torch.Size([768]), Grad: True\n",
            "Param Name: bert.encoder.layer.6.attention.output.LayerNorm.bias, Shape: torch.Size([768]), Grad: True\n",
            "Param Name: bert.encoder.layer.6.intermediate.dense.weight, Shape: torch.Size([3072, 768]), Grad: True\n",
            "Param Name: bert.encoder.layer.6.intermediate.dense.bias, Shape: torch.Size([3072]), Grad: True\n",
            "Param Name: bert.encoder.layer.6.output.dense.weight, Shape: torch.Size([768, 3072]), Grad: True\n",
            "Param Name: bert.encoder.layer.6.output.dense.bias, Shape: torch.Size([768]), Grad: True\n",
            "Param Name: bert.encoder.layer.6.output.LayerNorm.weight, Shape: torch.Size([768]), Grad: True\n",
            "Param Name: bert.encoder.layer.6.output.LayerNorm.bias, Shape: torch.Size([768]), Grad: True\n",
            "Param Name: bert.encoder.layer.7.attention.self.query.weight, Shape: torch.Size([768, 768]), Grad: True\n",
            "Param Name: bert.encoder.layer.7.attention.self.query.bias, Shape: torch.Size([768]), Grad: True\n",
            "Param Name: bert.encoder.layer.7.attention.self.key.weight, Shape: torch.Size([768, 768]), Grad: True\n",
            "Param Name: bert.encoder.layer.7.attention.self.key.bias, Shape: torch.Size([768]), Grad: True\n",
            "Param Name: bert.encoder.layer.7.attention.self.value.weight, Shape: torch.Size([768, 768]), Grad: True\n",
            "Param Name: bert.encoder.layer.7.attention.self.value.bias, Shape: torch.Size([768]), Grad: True\n",
            "Param Name: bert.encoder.layer.7.attention.output.dense.weight, Shape: torch.Size([768, 768]), Grad: True\n",
            "Param Name: bert.encoder.layer.7.attention.output.dense.bias, Shape: torch.Size([768]), Grad: True\n",
            "Param Name: bert.encoder.layer.7.attention.output.LayerNorm.weight, Shape: torch.Size([768]), Grad: True\n",
            "Param Name: bert.encoder.layer.7.attention.output.LayerNorm.bias, Shape: torch.Size([768]), Grad: True\n",
            "Param Name: bert.encoder.layer.7.intermediate.dense.weight, Shape: torch.Size([3072, 768]), Grad: True\n",
            "Param Name: bert.encoder.layer.7.intermediate.dense.bias, Shape: torch.Size([3072]), Grad: True\n",
            "Param Name: bert.encoder.layer.7.output.dense.weight, Shape: torch.Size([768, 3072]), Grad: True\n",
            "Param Name: bert.encoder.layer.7.output.dense.bias, Shape: torch.Size([768]), Grad: True\n",
            "Param Name: bert.encoder.layer.7.output.LayerNorm.weight, Shape: torch.Size([768]), Grad: True\n",
            "Param Name: bert.encoder.layer.7.output.LayerNorm.bias, Shape: torch.Size([768]), Grad: True\n",
            "Param Name: bert.encoder.layer.8.attention.self.query.weight, Shape: torch.Size([768, 768]), Grad: True\n",
            "Param Name: bert.encoder.layer.8.attention.self.query.bias, Shape: torch.Size([768]), Grad: True\n",
            "Param Name: bert.encoder.layer.8.attention.self.key.weight, Shape: torch.Size([768, 768]), Grad: True\n",
            "Param Name: bert.encoder.layer.8.attention.self.key.bias, Shape: torch.Size([768]), Grad: True\n",
            "Param Name: bert.encoder.layer.8.attention.self.value.weight, Shape: torch.Size([768, 768]), Grad: True\n",
            "Param Name: bert.encoder.layer.8.attention.self.value.bias, Shape: torch.Size([768]), Grad: True\n",
            "Param Name: bert.encoder.layer.8.attention.output.dense.weight, Shape: torch.Size([768, 768]), Grad: True\n",
            "Param Name: bert.encoder.layer.8.attention.output.dense.bias, Shape: torch.Size([768]), Grad: True\n",
            "Param Name: bert.encoder.layer.8.attention.output.LayerNorm.weight, Shape: torch.Size([768]), Grad: True\n",
            "Param Name: bert.encoder.layer.8.attention.output.LayerNorm.bias, Shape: torch.Size([768]), Grad: True\n",
            "Param Name: bert.encoder.layer.8.intermediate.dense.weight, Shape: torch.Size([3072, 768]), Grad: True\n",
            "Param Name: bert.encoder.layer.8.intermediate.dense.bias, Shape: torch.Size([3072]), Grad: True\n",
            "Param Name: bert.encoder.layer.8.output.dense.weight, Shape: torch.Size([768, 3072]), Grad: True\n",
            "Param Name: bert.encoder.layer.8.output.dense.bias, Shape: torch.Size([768]), Grad: True\n",
            "Param Name: bert.encoder.layer.8.output.LayerNorm.weight, Shape: torch.Size([768]), Grad: True\n",
            "Param Name: bert.encoder.layer.8.output.LayerNorm.bias, Shape: torch.Size([768]), Grad: True\n",
            "Param Name: bert.encoder.layer.9.attention.self.query.weight, Shape: torch.Size([768, 768]), Grad: True\n",
            "Param Name: bert.encoder.layer.9.attention.self.query.bias, Shape: torch.Size([768]), Grad: True\n",
            "Param Name: bert.encoder.layer.9.attention.self.key.weight, Shape: torch.Size([768, 768]), Grad: True\n",
            "Param Name: bert.encoder.layer.9.attention.self.key.bias, Shape: torch.Size([768]), Grad: True\n",
            "Param Name: bert.encoder.layer.9.attention.self.value.weight, Shape: torch.Size([768, 768]), Grad: True\n",
            "Param Name: bert.encoder.layer.9.attention.self.value.bias, Shape: torch.Size([768]), Grad: True\n",
            "Param Name: bert.encoder.layer.9.attention.output.dense.weight, Shape: torch.Size([768, 768]), Grad: True\n",
            "Param Name: bert.encoder.layer.9.attention.output.dense.bias, Shape: torch.Size([768]), Grad: True\n",
            "Param Name: bert.encoder.layer.9.attention.output.LayerNorm.weight, Shape: torch.Size([768]), Grad: True\n",
            "Param Name: bert.encoder.layer.9.attention.output.LayerNorm.bias, Shape: torch.Size([768]), Grad: True\n",
            "Param Name: bert.encoder.layer.9.intermediate.dense.weight, Shape: torch.Size([3072, 768]), Grad: True\n",
            "Param Name: bert.encoder.layer.9.intermediate.dense.bias, Shape: torch.Size([3072]), Grad: True\n",
            "Param Name: bert.encoder.layer.9.output.dense.weight, Shape: torch.Size([768, 3072]), Grad: True\n",
            "Param Name: bert.encoder.layer.9.output.dense.bias, Shape: torch.Size([768]), Grad: True\n",
            "Param Name: bert.encoder.layer.9.output.LayerNorm.weight, Shape: torch.Size([768]), Grad: True\n",
            "Param Name: bert.encoder.layer.9.output.LayerNorm.bias, Shape: torch.Size([768]), Grad: True\n",
            "Param Name: bert.encoder.layer.10.attention.self.query.weight, Shape: torch.Size([768, 768]), Grad: True\n",
            "Param Name: bert.encoder.layer.10.attention.self.query.bias, Shape: torch.Size([768]), Grad: True\n",
            "Param Name: bert.encoder.layer.10.attention.self.key.weight, Shape: torch.Size([768, 768]), Grad: True\n",
            "Param Name: bert.encoder.layer.10.attention.self.key.bias, Shape: torch.Size([768]), Grad: True\n",
            "Param Name: bert.encoder.layer.10.attention.self.value.weight, Shape: torch.Size([768, 768]), Grad: True\n",
            "Param Name: bert.encoder.layer.10.attention.self.value.bias, Shape: torch.Size([768]), Grad: True\n",
            "Param Name: bert.encoder.layer.10.attention.output.dense.weight, Shape: torch.Size([768, 768]), Grad: True\n",
            "Param Name: bert.encoder.layer.10.attention.output.dense.bias, Shape: torch.Size([768]), Grad: True\n",
            "Param Name: bert.encoder.layer.10.attention.output.LayerNorm.weight, Shape: torch.Size([768]), Grad: True\n",
            "Param Name: bert.encoder.layer.10.attention.output.LayerNorm.bias, Shape: torch.Size([768]), Grad: True\n",
            "Param Name: bert.encoder.layer.10.intermediate.dense.weight, Shape: torch.Size([3072, 768]), Grad: True\n",
            "Param Name: bert.encoder.layer.10.intermediate.dense.bias, Shape: torch.Size([3072]), Grad: True\n",
            "Param Name: bert.encoder.layer.10.output.dense.weight, Shape: torch.Size([768, 3072]), Grad: True\n",
            "Param Name: bert.encoder.layer.10.output.dense.bias, Shape: torch.Size([768]), Grad: True\n",
            "Param Name: bert.encoder.layer.10.output.LayerNorm.weight, Shape: torch.Size([768]), Grad: True\n",
            "Param Name: bert.encoder.layer.10.output.LayerNorm.bias, Shape: torch.Size([768]), Grad: True\n",
            "Param Name: bert.encoder.layer.11.attention.self.query.weight, Shape: torch.Size([768, 768]), Grad: True\n",
            "Param Name: bert.encoder.layer.11.attention.self.query.bias, Shape: torch.Size([768]), Grad: True\n",
            "Param Name: bert.encoder.layer.11.attention.self.key.weight, Shape: torch.Size([768, 768]), Grad: True\n",
            "Param Name: bert.encoder.layer.11.attention.self.key.bias, Shape: torch.Size([768]), Grad: True\n",
            "Param Name: bert.encoder.layer.11.attention.self.value.weight, Shape: torch.Size([768, 768]), Grad: True\n",
            "Param Name: bert.encoder.layer.11.attention.self.value.bias, Shape: torch.Size([768]), Grad: True\n",
            "Param Name: bert.encoder.layer.11.attention.output.dense.weight, Shape: torch.Size([768, 768]), Grad: True\n",
            "Param Name: bert.encoder.layer.11.attention.output.dense.bias, Shape: torch.Size([768]), Grad: True\n",
            "Param Name: bert.encoder.layer.11.attention.output.LayerNorm.weight, Shape: torch.Size([768]), Grad: True\n",
            "Param Name: bert.encoder.layer.11.attention.output.LayerNorm.bias, Shape: torch.Size([768]), Grad: True\n",
            "Param Name: bert.encoder.layer.11.intermediate.dense.weight, Shape: torch.Size([3072, 768]), Grad: True\n",
            "Param Name: bert.encoder.layer.11.intermediate.dense.bias, Shape: torch.Size([3072]), Grad: True\n",
            "Param Name: bert.encoder.layer.11.output.dense.weight, Shape: torch.Size([768, 3072]), Grad: True\n",
            "Param Name: bert.encoder.layer.11.output.dense.bias, Shape: torch.Size([768]), Grad: True\n",
            "Param Name: bert.encoder.layer.11.output.LayerNorm.weight, Shape: torch.Size([768]), Grad: True\n",
            "Param Name: bert.encoder.layer.11.output.LayerNorm.bias, Shape: torch.Size([768]), Grad: True\n",
            "Param Name: bert.pooler.dense.weight, Shape: torch.Size([768, 768]), Grad: True\n",
            "Param Name: bert.pooler.dense.bias, Shape: torch.Size([768]), Grad: True\n",
            "Param Name: classifier.0.weight, Shape: torch.Size([32, 768]), Grad: True\n",
            "Param Name: classifier.0.bias, Shape: torch.Size([32]), Grad: True\n",
            "Param Name: classifier.3.weight, Shape: torch.Size([2, 32]), Grad: True\n",
            "Param Name: classifier.3.bias, Shape: torch.Size([2]), Grad: True\n"
          ]
        }
      ],
      "source": [
        "for name, param in model_freeze.named_parameters():\n",
        "    print(f\"Param Name: {name}, Shape: {param.shape}, Grad: {param.requires_grad}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-31T13:48:34.491429Z",
          "start_time": "2022-01-31T13:48:34.486950Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QNQU8mnAUFxO",
        "outputId": "9dcbdff8-5b24-430c-a69d-47a4d851b7ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ],
      "source": [
        "for name, param in model_freeze.named_parameters():\n",
        "    if name == \"classifier.0.weight\":\n",
        "        print(param.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iIrHg1xUFxP"
      },
      "source": [
        "### 위 모델 (`model_freeze`)의 모든 파라미터의 gradient를 freeze 해보자"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-31T13:49:26.820569Z",
          "start_time": "2022-01-31T13:49:26.816511Z"
        },
        "id": "sHkaFgC8UFxP"
      },
      "outputs": [],
      "source": [
        "for param in model_freeze.parameters():\n",
        "    param.requires_grad=False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-31T13:49:31.951689Z",
          "start_time": "2022-01-31T13:49:31.934001Z"
        },
        "id": "PrDYEXnFUFxP",
        "outputId": "505d200b-9f09-42f6-b997-369c6cf8fb1f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Param Name: bert.embeddings.word_embeddings.weight, Shape: torch.Size([32000, 768]), Grad: False\n",
            "Param Name: bert.embeddings.position_embeddings.weight, Shape: torch.Size([512, 768]), Grad: False\n",
            "Param Name: bert.embeddings.token_type_embeddings.weight, Shape: torch.Size([2, 768]), Grad: False\n",
            "Param Name: bert.embeddings.LayerNorm.weight, Shape: torch.Size([768]), Grad: False\n",
            "Param Name: bert.embeddings.LayerNorm.bias, Shape: torch.Size([768]), Grad: False\n",
            "Param Name: bert.encoder.layer.0.attention.self.query.weight, Shape: torch.Size([768, 768]), Grad: False\n",
            "Param Name: bert.encoder.layer.0.attention.self.query.bias, Shape: torch.Size([768]), Grad: False\n",
            "Param Name: bert.encoder.layer.0.attention.self.key.weight, Shape: torch.Size([768, 768]), Grad: False\n",
            "Param Name: bert.encoder.layer.0.attention.self.key.bias, Shape: torch.Size([768]), Grad: False\n",
            "Param Name: bert.encoder.layer.0.attention.self.value.weight, Shape: torch.Size([768, 768]), Grad: False\n",
            "Param Name: bert.encoder.layer.0.attention.self.value.bias, Shape: torch.Size([768]), Grad: False\n",
            "Param Name: bert.encoder.layer.0.attention.output.dense.weight, Shape: torch.Size([768, 768]), Grad: False\n",
            "Param Name: bert.encoder.layer.0.attention.output.dense.bias, Shape: torch.Size([768]), Grad: False\n",
            "Param Name: bert.encoder.layer.0.attention.output.LayerNorm.weight, Shape: torch.Size([768]), Grad: False\n",
            "Param Name: bert.encoder.layer.0.attention.output.LayerNorm.bias, Shape: torch.Size([768]), Grad: False\n",
            "Param Name: bert.encoder.layer.0.intermediate.dense.weight, Shape: torch.Size([3072, 768]), Grad: False\n",
            "Param Name: bert.encoder.layer.0.intermediate.dense.bias, Shape: torch.Size([3072]), Grad: False\n",
            "Param Name: bert.encoder.layer.0.output.dense.weight, Shape: torch.Size([768, 3072]), Grad: False\n",
            "Param Name: bert.encoder.layer.0.output.dense.bias, Shape: torch.Size([768]), Grad: False\n",
            "Param Name: bert.encoder.layer.0.output.LayerNorm.weight, Shape: torch.Size([768]), Grad: False\n",
            "Param Name: bert.encoder.layer.0.output.LayerNorm.bias, Shape: torch.Size([768]), Grad: False\n",
            "Param Name: bert.encoder.layer.1.attention.self.query.weight, Shape: torch.Size([768, 768]), Grad: False\n",
            "Param Name: bert.encoder.layer.1.attention.self.query.bias, Shape: torch.Size([768]), Grad: False\n",
            "Param Name: bert.encoder.layer.1.attention.self.key.weight, Shape: torch.Size([768, 768]), Grad: False\n",
            "Param Name: bert.encoder.layer.1.attention.self.key.bias, Shape: torch.Size([768]), Grad: False\n",
            "Param Name: bert.encoder.layer.1.attention.self.value.weight, Shape: torch.Size([768, 768]), Grad: False\n",
            "Param Name: bert.encoder.layer.1.attention.self.value.bias, Shape: torch.Size([768]), Grad: False\n",
            "Param Name: bert.encoder.layer.1.attention.output.dense.weight, Shape: torch.Size([768, 768]), Grad: False\n",
            "Param Name: bert.encoder.layer.1.attention.output.dense.bias, Shape: torch.Size([768]), Grad: False\n",
            "Param Name: bert.encoder.layer.1.attention.output.LayerNorm.weight, Shape: torch.Size([768]), Grad: False\n",
            "Param Name: bert.encoder.layer.1.attention.output.LayerNorm.bias, Shape: torch.Size([768]), Grad: False\n",
            "Param Name: bert.encoder.layer.1.intermediate.dense.weight, Shape: torch.Size([3072, 768]), Grad: False\n",
            "Param Name: bert.encoder.layer.1.intermediate.dense.bias, Shape: torch.Size([3072]), Grad: False\n",
            "Param Name: bert.encoder.layer.1.output.dense.weight, Shape: torch.Size([768, 3072]), Grad: False\n",
            "Param Name: bert.encoder.layer.1.output.dense.bias, Shape: torch.Size([768]), Grad: False\n",
            "Param Name: bert.encoder.layer.1.output.LayerNorm.weight, Shape: torch.Size([768]), Grad: False\n",
            "Param Name: bert.encoder.layer.1.output.LayerNorm.bias, Shape: torch.Size([768]), Grad: False\n",
            "Param Name: bert.encoder.layer.2.attention.self.query.weight, Shape: torch.Size([768, 768]), Grad: False\n",
            "Param Name: bert.encoder.layer.2.attention.self.query.bias, Shape: torch.Size([768]), Grad: False\n",
            "Param Name: bert.encoder.layer.2.attention.self.key.weight, Shape: torch.Size([768, 768]), Grad: False\n",
            "Param Name: bert.encoder.layer.2.attention.self.key.bias, Shape: torch.Size([768]), Grad: False\n",
            "Param Name: bert.encoder.layer.2.attention.self.value.weight, Shape: torch.Size([768, 768]), Grad: False\n",
            "Param Name: bert.encoder.layer.2.attention.self.value.bias, Shape: torch.Size([768]), Grad: False\n",
            "Param Name: bert.encoder.layer.2.attention.output.dense.weight, Shape: torch.Size([768, 768]), Grad: False\n",
            "Param Name: bert.encoder.layer.2.attention.output.dense.bias, Shape: torch.Size([768]), Grad: False\n",
            "Param Name: bert.encoder.layer.2.attention.output.LayerNorm.weight, Shape: torch.Size([768]), Grad: False\n",
            "Param Name: bert.encoder.layer.2.attention.output.LayerNorm.bias, Shape: torch.Size([768]), Grad: False\n",
            "Param Name: bert.encoder.layer.2.intermediate.dense.weight, Shape: torch.Size([3072, 768]), Grad: False\n",
            "Param Name: bert.encoder.layer.2.intermediate.dense.bias, Shape: torch.Size([3072]), Grad: False\n",
            "Param Name: bert.encoder.layer.2.output.dense.weight, Shape: torch.Size([768, 3072]), Grad: False\n",
            "Param Name: bert.encoder.layer.2.output.dense.bias, Shape: torch.Size([768]), Grad: False\n",
            "Param Name: bert.encoder.layer.2.output.LayerNorm.weight, Shape: torch.Size([768]), Grad: False\n",
            "Param Name: bert.encoder.layer.2.output.LayerNorm.bias, Shape: torch.Size([768]), Grad: False\n",
            "Param Name: bert.encoder.layer.3.attention.self.query.weight, Shape: torch.Size([768, 768]), Grad: False\n",
            "Param Name: bert.encoder.layer.3.attention.self.query.bias, Shape: torch.Size([768]), Grad: False\n",
            "Param Name: bert.encoder.layer.3.attention.self.key.weight, Shape: torch.Size([768, 768]), Grad: False\n",
            "Param Name: bert.encoder.layer.3.attention.self.key.bias, Shape: torch.Size([768]), Grad: False\n",
            "Param Name: bert.encoder.layer.3.attention.self.value.weight, Shape: torch.Size([768, 768]), Grad: False\n",
            "Param Name: bert.encoder.layer.3.attention.self.value.bias, Shape: torch.Size([768]), Grad: False\n",
            "Param Name: bert.encoder.layer.3.attention.output.dense.weight, Shape: torch.Size([768, 768]), Grad: False\n",
            "Param Name: bert.encoder.layer.3.attention.output.dense.bias, Shape: torch.Size([768]), Grad: False\n",
            "Param Name: bert.encoder.layer.3.attention.output.LayerNorm.weight, Shape: torch.Size([768]), Grad: False\n",
            "Param Name: bert.encoder.layer.3.attention.output.LayerNorm.bias, Shape: torch.Size([768]), Grad: False\n",
            "Param Name: bert.encoder.layer.3.intermediate.dense.weight, Shape: torch.Size([3072, 768]), Grad: False\n",
            "Param Name: bert.encoder.layer.3.intermediate.dense.bias, Shape: torch.Size([3072]), Grad: False\n",
            "Param Name: bert.encoder.layer.3.output.dense.weight, Shape: torch.Size([768, 3072]), Grad: False\n",
            "Param Name: bert.encoder.layer.3.output.dense.bias, Shape: torch.Size([768]), Grad: False\n",
            "Param Name: bert.encoder.layer.3.output.LayerNorm.weight, Shape: torch.Size([768]), Grad: False\n",
            "Param Name: bert.encoder.layer.3.output.LayerNorm.bias, Shape: torch.Size([768]), Grad: False\n",
            "Param Name: bert.encoder.layer.4.attention.self.query.weight, Shape: torch.Size([768, 768]), Grad: False\n",
            "Param Name: bert.encoder.layer.4.attention.self.query.bias, Shape: torch.Size([768]), Grad: False\n",
            "Param Name: bert.encoder.layer.4.attention.self.key.weight, Shape: torch.Size([768, 768]), Grad: False\n",
            "Param Name: bert.encoder.layer.4.attention.self.key.bias, Shape: torch.Size([768]), Grad: False\n",
            "Param Name: bert.encoder.layer.4.attention.self.value.weight, Shape: torch.Size([768, 768]), Grad: False\n",
            "Param Name: bert.encoder.layer.4.attention.self.value.bias, Shape: torch.Size([768]), Grad: False\n",
            "Param Name: bert.encoder.layer.4.attention.output.dense.weight, Shape: torch.Size([768, 768]), Grad: False\n",
            "Param Name: bert.encoder.layer.4.attention.output.dense.bias, Shape: torch.Size([768]), Grad: False\n",
            "Param Name: bert.encoder.layer.4.attention.output.LayerNorm.weight, Shape: torch.Size([768]), Grad: False\n",
            "Param Name: bert.encoder.layer.4.attention.output.LayerNorm.bias, Shape: torch.Size([768]), Grad: False\n",
            "Param Name: bert.encoder.layer.4.intermediate.dense.weight, Shape: torch.Size([3072, 768]), Grad: False\n",
            "Param Name: bert.encoder.layer.4.intermediate.dense.bias, Shape: torch.Size([3072]), Grad: False\n",
            "Param Name: bert.encoder.layer.4.output.dense.weight, Shape: torch.Size([768, 3072]), Grad: False\n",
            "Param Name: bert.encoder.layer.4.output.dense.bias, Shape: torch.Size([768]), Grad: False\n",
            "Param Name: bert.encoder.layer.4.output.LayerNorm.weight, Shape: torch.Size([768]), Grad: False\n",
            "Param Name: bert.encoder.layer.4.output.LayerNorm.bias, Shape: torch.Size([768]), Grad: False\n",
            "Param Name: bert.encoder.layer.5.attention.self.query.weight, Shape: torch.Size([768, 768]), Grad: False\n",
            "Param Name: bert.encoder.layer.5.attention.self.query.bias, Shape: torch.Size([768]), Grad: False\n",
            "Param Name: bert.encoder.layer.5.attention.self.key.weight, Shape: torch.Size([768, 768]), Grad: False\n",
            "Param Name: bert.encoder.layer.5.attention.self.key.bias, Shape: torch.Size([768]), Grad: False\n",
            "Param Name: bert.encoder.layer.5.attention.self.value.weight, Shape: torch.Size([768, 768]), Grad: False\n",
            "Param Name: bert.encoder.layer.5.attention.self.value.bias, Shape: torch.Size([768]), Grad: False\n",
            "Param Name: bert.encoder.layer.5.attention.output.dense.weight, Shape: torch.Size([768, 768]), Grad: False\n",
            "Param Name: bert.encoder.layer.5.attention.output.dense.bias, Shape: torch.Size([768]), Grad: False\n",
            "Param Name: bert.encoder.layer.5.attention.output.LayerNorm.weight, Shape: torch.Size([768]), Grad: False\n",
            "Param Name: bert.encoder.layer.5.attention.output.LayerNorm.bias, Shape: torch.Size([768]), Grad: False\n",
            "Param Name: bert.encoder.layer.5.intermediate.dense.weight, Shape: torch.Size([3072, 768]), Grad: False\n",
            "Param Name: bert.encoder.layer.5.intermediate.dense.bias, Shape: torch.Size([3072]), Grad: False\n",
            "Param Name: bert.encoder.layer.5.output.dense.weight, Shape: torch.Size([768, 3072]), Grad: False\n",
            "Param Name: bert.encoder.layer.5.output.dense.bias, Shape: torch.Size([768]), Grad: False\n",
            "Param Name: bert.encoder.layer.5.output.LayerNorm.weight, Shape: torch.Size([768]), Grad: False\n",
            "Param Name: bert.encoder.layer.5.output.LayerNorm.bias, Shape: torch.Size([768]), Grad: False\n",
            "Param Name: bert.encoder.layer.6.attention.self.query.weight, Shape: torch.Size([768, 768]), Grad: False\n",
            "Param Name: bert.encoder.layer.6.attention.self.query.bias, Shape: torch.Size([768]), Grad: False\n",
            "Param Name: bert.encoder.layer.6.attention.self.key.weight, Shape: torch.Size([768, 768]), Grad: False\n",
            "Param Name: bert.encoder.layer.6.attention.self.key.bias, Shape: torch.Size([768]), Grad: False\n",
            "Param Name: bert.encoder.layer.6.attention.self.value.weight, Shape: torch.Size([768, 768]), Grad: False\n",
            "Param Name: bert.encoder.layer.6.attention.self.value.bias, Shape: torch.Size([768]), Grad: False\n",
            "Param Name: bert.encoder.layer.6.attention.output.dense.weight, Shape: torch.Size([768, 768]), Grad: False\n",
            "Param Name: bert.encoder.layer.6.attention.output.dense.bias, Shape: torch.Size([768]), Grad: False\n",
            "Param Name: bert.encoder.layer.6.attention.output.LayerNorm.weight, Shape: torch.Size([768]), Grad: False\n",
            "Param Name: bert.encoder.layer.6.attention.output.LayerNorm.bias, Shape: torch.Size([768]), Grad: False\n",
            "Param Name: bert.encoder.layer.6.intermediate.dense.weight, Shape: torch.Size([3072, 768]), Grad: False\n",
            "Param Name: bert.encoder.layer.6.intermediate.dense.bias, Shape: torch.Size([3072]), Grad: False\n",
            "Param Name: bert.encoder.layer.6.output.dense.weight, Shape: torch.Size([768, 3072]), Grad: False\n",
            "Param Name: bert.encoder.layer.6.output.dense.bias, Shape: torch.Size([768]), Grad: False\n",
            "Param Name: bert.encoder.layer.6.output.LayerNorm.weight, Shape: torch.Size([768]), Grad: False\n",
            "Param Name: bert.encoder.layer.6.output.LayerNorm.bias, Shape: torch.Size([768]), Grad: False\n",
            "Param Name: bert.encoder.layer.7.attention.self.query.weight, Shape: torch.Size([768, 768]), Grad: False\n",
            "Param Name: bert.encoder.layer.7.attention.self.query.bias, Shape: torch.Size([768]), Grad: False\n",
            "Param Name: bert.encoder.layer.7.attention.self.key.weight, Shape: torch.Size([768, 768]), Grad: False\n",
            "Param Name: bert.encoder.layer.7.attention.self.key.bias, Shape: torch.Size([768]), Grad: False\n",
            "Param Name: bert.encoder.layer.7.attention.self.value.weight, Shape: torch.Size([768, 768]), Grad: False\n",
            "Param Name: bert.encoder.layer.7.attention.self.value.bias, Shape: torch.Size([768]), Grad: False\n",
            "Param Name: bert.encoder.layer.7.attention.output.dense.weight, Shape: torch.Size([768, 768]), Grad: False\n",
            "Param Name: bert.encoder.layer.7.attention.output.dense.bias, Shape: torch.Size([768]), Grad: False\n",
            "Param Name: bert.encoder.layer.7.attention.output.LayerNorm.weight, Shape: torch.Size([768]), Grad: False\n",
            "Param Name: bert.encoder.layer.7.attention.output.LayerNorm.bias, Shape: torch.Size([768]), Grad: False\n",
            "Param Name: bert.encoder.layer.7.intermediate.dense.weight, Shape: torch.Size([3072, 768]), Grad: False\n",
            "Param Name: bert.encoder.layer.7.intermediate.dense.bias, Shape: torch.Size([3072]), Grad: False\n",
            "Param Name: bert.encoder.layer.7.output.dense.weight, Shape: torch.Size([768, 3072]), Grad: False\n",
            "Param Name: bert.encoder.layer.7.output.dense.bias, Shape: torch.Size([768]), Grad: False\n",
            "Param Name: bert.encoder.layer.7.output.LayerNorm.weight, Shape: torch.Size([768]), Grad: False\n",
            "Param Name: bert.encoder.layer.7.output.LayerNorm.bias, Shape: torch.Size([768]), Grad: False\n",
            "Param Name: bert.encoder.layer.8.attention.self.query.weight, Shape: torch.Size([768, 768]), Grad: False\n",
            "Param Name: bert.encoder.layer.8.attention.self.query.bias, Shape: torch.Size([768]), Grad: False\n",
            "Param Name: bert.encoder.layer.8.attention.self.key.weight, Shape: torch.Size([768, 768]), Grad: False\n",
            "Param Name: bert.encoder.layer.8.attention.self.key.bias, Shape: torch.Size([768]), Grad: False\n",
            "Param Name: bert.encoder.layer.8.attention.self.value.weight, Shape: torch.Size([768, 768]), Grad: False\n",
            "Param Name: bert.encoder.layer.8.attention.self.value.bias, Shape: torch.Size([768]), Grad: False\n",
            "Param Name: bert.encoder.layer.8.attention.output.dense.weight, Shape: torch.Size([768, 768]), Grad: False\n",
            "Param Name: bert.encoder.layer.8.attention.output.dense.bias, Shape: torch.Size([768]), Grad: False\n",
            "Param Name: bert.encoder.layer.8.attention.output.LayerNorm.weight, Shape: torch.Size([768]), Grad: False\n",
            "Param Name: bert.encoder.layer.8.attention.output.LayerNorm.bias, Shape: torch.Size([768]), Grad: False\n",
            "Param Name: bert.encoder.layer.8.intermediate.dense.weight, Shape: torch.Size([3072, 768]), Grad: False\n",
            "Param Name: bert.encoder.layer.8.intermediate.dense.bias, Shape: torch.Size([3072]), Grad: False\n",
            "Param Name: bert.encoder.layer.8.output.dense.weight, Shape: torch.Size([768, 3072]), Grad: False\n",
            "Param Name: bert.encoder.layer.8.output.dense.bias, Shape: torch.Size([768]), Grad: False\n",
            "Param Name: bert.encoder.layer.8.output.LayerNorm.weight, Shape: torch.Size([768]), Grad: False\n",
            "Param Name: bert.encoder.layer.8.output.LayerNorm.bias, Shape: torch.Size([768]), Grad: False\n",
            "Param Name: bert.encoder.layer.9.attention.self.query.weight, Shape: torch.Size([768, 768]), Grad: False\n",
            "Param Name: bert.encoder.layer.9.attention.self.query.bias, Shape: torch.Size([768]), Grad: False\n",
            "Param Name: bert.encoder.layer.9.attention.self.key.weight, Shape: torch.Size([768, 768]), Grad: False\n",
            "Param Name: bert.encoder.layer.9.attention.self.key.bias, Shape: torch.Size([768]), Grad: False\n",
            "Param Name: bert.encoder.layer.9.attention.self.value.weight, Shape: torch.Size([768, 768]), Grad: False\n",
            "Param Name: bert.encoder.layer.9.attention.self.value.bias, Shape: torch.Size([768]), Grad: False\n",
            "Param Name: bert.encoder.layer.9.attention.output.dense.weight, Shape: torch.Size([768, 768]), Grad: False\n",
            "Param Name: bert.encoder.layer.9.attention.output.dense.bias, Shape: torch.Size([768]), Grad: False\n",
            "Param Name: bert.encoder.layer.9.attention.output.LayerNorm.weight, Shape: torch.Size([768]), Grad: False\n",
            "Param Name: bert.encoder.layer.9.attention.output.LayerNorm.bias, Shape: torch.Size([768]), Grad: False\n",
            "Param Name: bert.encoder.layer.9.intermediate.dense.weight, Shape: torch.Size([3072, 768]), Grad: False\n",
            "Param Name: bert.encoder.layer.9.intermediate.dense.bias, Shape: torch.Size([3072]), Grad: False\n",
            "Param Name: bert.encoder.layer.9.output.dense.weight, Shape: torch.Size([768, 3072]), Grad: False\n",
            "Param Name: bert.encoder.layer.9.output.dense.bias, Shape: torch.Size([768]), Grad: False\n",
            "Param Name: bert.encoder.layer.9.output.LayerNorm.weight, Shape: torch.Size([768]), Grad: False\n",
            "Param Name: bert.encoder.layer.9.output.LayerNorm.bias, Shape: torch.Size([768]), Grad: False\n",
            "Param Name: bert.encoder.layer.10.attention.self.query.weight, Shape: torch.Size([768, 768]), Grad: False\n",
            "Param Name: bert.encoder.layer.10.attention.self.query.bias, Shape: torch.Size([768]), Grad: False\n",
            "Param Name: bert.encoder.layer.10.attention.self.key.weight, Shape: torch.Size([768, 768]), Grad: False\n",
            "Param Name: bert.encoder.layer.10.attention.self.key.bias, Shape: torch.Size([768]), Grad: False\n",
            "Param Name: bert.encoder.layer.10.attention.self.value.weight, Shape: torch.Size([768, 768]), Grad: False\n",
            "Param Name: bert.encoder.layer.10.attention.self.value.bias, Shape: torch.Size([768]), Grad: False\n",
            "Param Name: bert.encoder.layer.10.attention.output.dense.weight, Shape: torch.Size([768, 768]), Grad: False\n",
            "Param Name: bert.encoder.layer.10.attention.output.dense.bias, Shape: torch.Size([768]), Grad: False\n",
            "Param Name: bert.encoder.layer.10.attention.output.LayerNorm.weight, Shape: torch.Size([768]), Grad: False\n",
            "Param Name: bert.encoder.layer.10.attention.output.LayerNorm.bias, Shape: torch.Size([768]), Grad: False\n",
            "Param Name: bert.encoder.layer.10.intermediate.dense.weight, Shape: torch.Size([3072, 768]), Grad: False\n",
            "Param Name: bert.encoder.layer.10.intermediate.dense.bias, Shape: torch.Size([3072]), Grad: False\n",
            "Param Name: bert.encoder.layer.10.output.dense.weight, Shape: torch.Size([768, 3072]), Grad: False\n",
            "Param Name: bert.encoder.layer.10.output.dense.bias, Shape: torch.Size([768]), Grad: False\n",
            "Param Name: bert.encoder.layer.10.output.LayerNorm.weight, Shape: torch.Size([768]), Grad: False\n",
            "Param Name: bert.encoder.layer.10.output.LayerNorm.bias, Shape: torch.Size([768]), Grad: False\n",
            "Param Name: bert.encoder.layer.11.attention.self.query.weight, Shape: torch.Size([768, 768]), Grad: False\n",
            "Param Name: bert.encoder.layer.11.attention.self.query.bias, Shape: torch.Size([768]), Grad: False\n",
            "Param Name: bert.encoder.layer.11.attention.self.key.weight, Shape: torch.Size([768, 768]), Grad: False\n",
            "Param Name: bert.encoder.layer.11.attention.self.key.bias, Shape: torch.Size([768]), Grad: False\n",
            "Param Name: bert.encoder.layer.11.attention.self.value.weight, Shape: torch.Size([768, 768]), Grad: False\n",
            "Param Name: bert.encoder.layer.11.attention.self.value.bias, Shape: torch.Size([768]), Grad: False\n",
            "Param Name: bert.encoder.layer.11.attention.output.dense.weight, Shape: torch.Size([768, 768]), Grad: False\n",
            "Param Name: bert.encoder.layer.11.attention.output.dense.bias, Shape: torch.Size([768]), Grad: False\n",
            "Param Name: bert.encoder.layer.11.attention.output.LayerNorm.weight, Shape: torch.Size([768]), Grad: False\n",
            "Param Name: bert.encoder.layer.11.attention.output.LayerNorm.bias, Shape: torch.Size([768]), Grad: False\n",
            "Param Name: bert.encoder.layer.11.intermediate.dense.weight, Shape: torch.Size([3072, 768]), Grad: False\n",
            "Param Name: bert.encoder.layer.11.intermediate.dense.bias, Shape: torch.Size([3072]), Grad: False\n",
            "Param Name: bert.encoder.layer.11.output.dense.weight, Shape: torch.Size([768, 3072]), Grad: False\n",
            "Param Name: bert.encoder.layer.11.output.dense.bias, Shape: torch.Size([768]), Grad: False\n",
            "Param Name: bert.encoder.layer.11.output.LayerNorm.weight, Shape: torch.Size([768]), Grad: False\n",
            "Param Name: bert.encoder.layer.11.output.LayerNorm.bias, Shape: torch.Size([768]), Grad: False\n",
            "Param Name: bert.pooler.dense.weight, Shape: torch.Size([768, 768]), Grad: False\n",
            "Param Name: bert.pooler.dense.bias, Shape: torch.Size([768]), Grad: False\n",
            "Param Name: classifier.0.weight, Shape: torch.Size([32, 768]), Grad: False\n",
            "Param Name: classifier.0.bias, Shape: torch.Size([32]), Grad: False\n",
            "Param Name: classifier.3.weight, Shape: torch.Size([2, 32]), Grad: False\n",
            "Param Name: classifier.3.bias, Shape: torch.Size([2]), Grad: False\n"
          ]
        }
      ],
      "source": [
        "# 확인\n",
        "for name, param in model_freeze.named_parameters():\n",
        "    print(f\"Param Name: {name}, Shape: {param.shape}, Grad: {param.requires_grad}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bhBZGJ4IaMev"
      },
      "source": [
        "## Challenge"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afiwEOQgaMev"
      },
      "source": [
        "### `scheduler` 를 생성 \n",
        "- 스케쥴러를 알기 전에 먼저 `epoch`의 개념을 알아야 한다. Epoch는 dataset를 **몇 번 반복**해 학습할 것인지를 의미한다. 만약 dataset의 개수가 2,000개이고 epoch을 2번 학습하게 되면 총 4,000개의 데이터를 학습하게 된다.   \n",
        "- 스케쥴러는 epoch에 따라 learning rate의 값을 조정하는 것을 의미한다. \n",
        "- `torch.optim.lr_scheduler`는 학습이 진행되면서 learning rate를 조절할 수 있는 다양한 함수를 제공한다. \n",
        "- 예를 들어 [여기](https://huggingface.co/docs/transformers/main_classes/optimizer_schedules#transformers.get_linear_schedule_with_warmup)의 그림에서 볼 수 있듯이 warup scheduler는 특정 step까지는 learning rate를 천천히 상승시키다가 고점에 도달하면 다시 하락시킨다. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Gte_JRMaMev"
      },
      "source": [
        "### `model`, `optimizer`, `scheduler`를 초기화하는 함수를 구현하라"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-02T04:01:59.217735Z",
          "start_time": "2022-02-02T04:01:59.210482Z"
        },
        "id": "-sE7xjYcRD1p"
      },
      "outputs": [],
      "source": [
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.optim import AdamW\n",
        "from torch.nn.utils import clip_grad_norm_\n",
        "from transformers import get_linear_schedule_with_warmup, get_constant_schedule"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-02T04:01:59.549660Z",
          "start_time": "2022-02-02T04:01:59.545752Z"
        },
        "id": "2eTFXzy8VK9R"
      },
      "outputs": [],
      "source": [
        "def initializer(train_dataloader, epochs=2):\n",
        "    \"\"\"\n",
        "    모델, 옵티마이저, 스케쥴러 초기화\n",
        "    \"\"\"\n",
        "    \n",
        "    model = CustomClassifier(hidden_size=768, n_label=2)\n",
        "\n",
        "    optimizer = AdamW(\n",
        "        model.parameters(), # update 대상 파라미터를 입력\n",
        "        lr=2e-5,\n",
        "        eps=1e-8\n",
        "    )\n",
        "    \n",
        "    total_steps = len(train_dataloader) * epochs\n",
        "    print(f\"Total train steps with {epochs} epochs: {total_steps}\")\n",
        "\n",
        "    scheduler = get_linear_schedule_with_warmup(\n",
        "        optimizer, \n",
        "        num_warmup_steps = 0, # 여기서는 warmup을 사용하지 않는다.\n",
        "        num_training_steps = total_steps\n",
        "    )\n",
        "\n",
        "    return model, optimizer, scheduler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NukaJc15UFxQ"
      },
      "source": [
        "### `train()` 함수에 `epoch`와 `clip_grad_norm` 추가\n",
        "- data_loader 학습을 `epoch`만큼 반복하도록 함수를 수정하라\n",
        "- gradient cliping은 미분 값 너무 큰 경우 gradient exploding되는 현상을 막기 위해 미분값이 `threshold`를 넘을 경우 특정 비율을 미분 값에 곱해 크기를 줄여준다.\n",
        "- [official document](https://pytorch.org/docs/stable/generated/torch.nn.utils.clip_grad_norm_.html)\n",
        "- [한국어 설명](https://kh-kim.gitbook.io/natural-language-processing-with-pytorch/00-cover-6/05-gradient-clipping)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JLtIHztaMew"
      },
      "source": [
        "### model, optimizer, scheduler의 파라미터 저장 함수 구현후 추가"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-02T04:02:02.786877Z",
          "start_time": "2022-02-02T04:02:02.783726Z"
        },
        "id": "FyGTTZXWaMew"
      },
      "outputs": [],
      "source": [
        "def save_checkpoint(path, model, optimizer, scheduler, epoch, loss):\n",
        "    file_name = f'{path}/model.ckpt.{epoch}'\n",
        "    \n",
        "    torch.save(\n",
        "        {\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'scheduler_state_dict': scheduler.state_dict(),\n",
        "            'loss' : loss\n",
        "        }, \n",
        "        file_name\n",
        "    )\n",
        "    \n",
        "    print(f\"Saving epoch {epoch} checkpoint at {file_name}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-02T04:02:10.624280Z",
          "start_time": "2022-02-02T04:02:10.615781Z"
        },
        "id": "ZvY5rxDKHQAp"
      },
      "outputs": [],
      "source": [
        "loss_fct = CrossEntropyLoss()\n",
        "\n",
        "def train(model, train_dataloader, valid_dataloader=None, epochs=2):\n",
        "        \n",
        "        # train_dataloaer 학습을 epochs만큼 반복\n",
        "        for epoch in range(epochs):\n",
        "            print(f\"*****Epoch {epoch} Train Start*****\")\n",
        "            \n",
        "            # 배치 단위 평균 loss와 총 평균 loss 계산하기위해 변수 생성\n",
        "            total_loss, batch_loss, batch_count = 0,0,0\n",
        "        \n",
        "            # model을 train 모드로 설정 & device 할당\n",
        "            model.train()\n",
        "            model.to(device)\n",
        "            \n",
        "            # data iterator를 돌면서 하나씩 학습\n",
        "            for step, batch in enumerate(train_dataloader):\n",
        "                batch_count+=1\n",
        "                \n",
        "                # tensor 연산 전, 각 tensor에 device 할당\n",
        "                batch = tuple(item.to(device) for item in batch)\n",
        "            \n",
        "                batch_input, batch_label = batch\n",
        "            \n",
        "                # batch마다 모델이 갖고 있는 기존 gradient를 초기화\n",
        "                model.zero_grad()\n",
        "            \n",
        "                # forward\n",
        "                logits = model(**batch_input)\n",
        "            \n",
        "                # loss\n",
        "                loss = loss_fct(logits, batch_label)\n",
        "                batch_loss += loss.item()\n",
        "                total_loss += loss.item()\n",
        "            \n",
        "                # backward -> 파라미터의 미분(gradient)를 자동으로 계산\n",
        "                loss.backward()\n",
        "                \n",
        "                # gradient clipping 적용 \n",
        "                clip_grad_norm_(model.parameters(), 1.0)\n",
        "                \n",
        "                # optimizer & scheduler 업데이트\n",
        "                optimizer.step()\n",
        "                scheduler.step()\n",
        "                \n",
        "                # 배치 10개씩 처리할 때마다 평균 loss와 lr를 출력\n",
        "                if (step % 10 == 0 and step != 0):\n",
        "                    learning_rate = optimizer.param_groups[0]['lr']\n",
        "                    print(f\"Epoch: {epoch}, Step : {step}, LR : {learning_rate}, Avg Loss : {batch_loss / batch_count:.4f}\")\n",
        "\n",
        "                    # reset \n",
        "                    batch_loss, batch_count = 0,0\n",
        "\n",
        "            print(f\"Epoch {epoch} Total Mean Loss : {total_loss/(step+1):.4f}\")\n",
        "            print(f\"*****Epoch {epoch} Train Finish*****\\n\")\n",
        "            \n",
        "            if valid_dataloader is not None:\n",
        "                print(f\"*****Epoch {epoch} Valid Start*****\")\n",
        "                valid_loss, valid_acc = validate(model, valid_dataloader)\n",
        "                print(f\"Epoch {epoch} Valid Loss : {valid_loss:.4f} Valid Acc : {valid_acc:.2f}\")\n",
        "                print(f\"*****Epoch {epoch} Valid Finish*****\\n\")\n",
        "            \n",
        "            # checkpoint 저장\n",
        "            save_checkpoint(\".\", model, optimizer, scheduler, epoch, total_loss/(step+1))\n",
        "                \n",
        "        print(\"Train Completed. End Program.\")\n",
        "                \n",
        "            \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ig0mabXzaMex"
      },
      "source": [
        "### `validate()` 함수 구현 \n",
        "- `validate()` 함수 내 model의 상태는 **evaluate**이어야 한다. evaluate 상태의 model은 dropout을 진행하지 않는다. \n",
        "- **forward**를 진행할 때 `with torch.no_grad(): ...` 설정해 미분 계산을 방지한다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-02T04:02:11.636684Z",
          "start_time": "2022-02-02T04:02:11.631550Z"
        },
        "id": "VHpuV0CXUFxR"
      },
      "outputs": [],
      "source": [
        "def validate(model, valid_dataloader):\n",
        "   \n",
        "    # 모델을 evaluate 모드로 설정 & device 할당\n",
        "    model.eval()\n",
        "    model.to(device)\n",
        "    \n",
        "    total_loss, total_acc= 0,0\n",
        "        \n",
        "    for step, batch in enumerate(valid_dataloader):\n",
        "        \n",
        "        # tensor 연산 전, 각 tensor에 device 할당\n",
        "        batch = tuple(item.to(device) for item in batch)\n",
        "            \n",
        "        batch_input, batch_label = batch\n",
        "            \n",
        "        # gradient 계산하지 않음\n",
        "        with torch.no_grad():\n",
        "            logits = model(**batch_input)\n",
        "            \n",
        "        # loss\n",
        "        loss = loss_fct(logits, batch_label)\n",
        "        total_loss += loss.item()\n",
        "        \n",
        "        # accuracy\n",
        "        probs = F.softmax(logits, dim=1)\n",
        "        preds = torch.argmax(probs, dim=1).flatten()\n",
        "        acc = (preds == batch_label).cpu().numpy().mean()\n",
        "        total_acc+=acc\n",
        "    \n",
        "    total_loss = total_loss/(step+1)\n",
        "    total_acc = total_acc/(step+1)*100\n",
        "\n",
        "    return total_loss, total_acc\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NWKzxIaf1QJ"
      },
      "source": [
        "## Advanced"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1cVoX1W6aMey"
      },
      "source": [
        "### 학습 데이터를 epoch 4까지 학습\n",
        "- 매 epoch마다 다음을 수행한다.\n",
        "  - 학습이 끝난 후 validate() 함수 실행 \n",
        "  - validate() 함수가 끝난 후 model save 함수 실행"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-02T06:02:11.377612Z",
          "start_time": "2022-02-02T04:02:20.931961Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7Er1qKtsf1QJ",
        "outputId": "dbe48c0b-f153-4444-917f-458d588543e1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total train steps with 4 epochs: 1128\n",
            "*****Epoch 0 Train Start*****\n",
            "Epoch: 0, Step : 10, LR : 1.9804964539007094e-05, Avg Loss : 0.6575\n",
            "Epoch: 0, Step : 20, LR : 1.962765957446809e-05, Avg Loss : 0.5423\n",
            "Epoch: 0, Step : 30, LR : 1.945035460992908e-05, Avg Loss : 0.4294\n",
            "Epoch: 0, Step : 40, LR : 1.927304964539007e-05, Avg Loss : 0.3722\n",
            "Epoch: 0, Step : 50, LR : 1.9095744680851064e-05, Avg Loss : 0.4194\n",
            "Epoch: 0, Step : 60, LR : 1.891843971631206e-05, Avg Loss : 0.3813\n",
            "Epoch: 0, Step : 70, LR : 1.8741134751773053e-05, Avg Loss : 0.4254\n",
            "Epoch: 0, Step : 80, LR : 1.8563829787234043e-05, Avg Loss : 0.4150\n",
            "Epoch: 0, Step : 90, LR : 1.8386524822695038e-05, Avg Loss : 0.3666\n",
            "Epoch: 0, Step : 100, LR : 1.8209219858156032e-05, Avg Loss : 0.3757\n",
            "Epoch: 0, Step : 110, LR : 1.8031914893617023e-05, Avg Loss : 0.3526\n",
            "Epoch: 0, Step : 120, LR : 1.7854609929078013e-05, Avg Loss : 0.3910\n",
            "Epoch: 0, Step : 130, LR : 1.7677304964539008e-05, Avg Loss : 0.3356\n",
            "Epoch: 0, Step : 140, LR : 1.7500000000000002e-05, Avg Loss : 0.3347\n",
            "Epoch: 0, Step : 150, LR : 1.7322695035460996e-05, Avg Loss : 0.3763\n",
            "Epoch: 0, Step : 160, LR : 1.7145390070921987e-05, Avg Loss : 0.3518\n",
            "Epoch: 0, Step : 170, LR : 1.696808510638298e-05, Avg Loss : 0.3173\n",
            "Epoch: 0, Step : 180, LR : 1.6790780141843972e-05, Avg Loss : 0.3746\n",
            "Epoch: 0, Step : 190, LR : 1.6613475177304966e-05, Avg Loss : 0.3875\n",
            "Epoch: 0, Step : 200, LR : 1.6436170212765957e-05, Avg Loss : 0.3244\n",
            "Epoch: 0, Step : 210, LR : 1.625886524822695e-05, Avg Loss : 0.4051\n",
            "Epoch: 0, Step : 220, LR : 1.6081560283687945e-05, Avg Loss : 0.2834\n",
            "Epoch: 0, Step : 230, LR : 1.590425531914894e-05, Avg Loss : 0.3808\n",
            "Epoch: 0, Step : 240, LR : 1.572695035460993e-05, Avg Loss : 0.2998\n",
            "Epoch: 0, Step : 250, LR : 1.5549645390070924e-05, Avg Loss : 0.3110\n",
            "Epoch: 0, Step : 260, LR : 1.5372340425531915e-05, Avg Loss : 0.3228\n",
            "Epoch: 0, Step : 270, LR : 1.5195035460992908e-05, Avg Loss : 0.2687\n",
            "Epoch: 0, Step : 280, LR : 1.5017730496453902e-05, Avg Loss : 0.2982\n",
            "Epoch 0 Total Mean Loss : 0.3748\n",
            "*****Epoch 0 Train Finish*****\n",
            "\n",
            "*****Epoch 0 Valid Start*****\n",
            "Epoch 0 Valid Loss : 0.3558 Valid Acc : 84.41\n",
            "*****Epoch 0 Valid Finish*****\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/bis/miniconda3/envs/torch/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:216: UserWarning: Please also save or load the state of the optimizer when saving or loading the scheduler.\n",
            "  warnings.warn(SAVE_STATE_WARNING, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving epoch 0 checkpoint at ./model.ckpt.0\n",
            "*****Epoch 1 Train Start*****\n",
            "Epoch: 1, Step : 10, LR : 1.4804964539007095e-05, Avg Loss : 0.2260\n",
            "Epoch: 1, Step : 20, LR : 1.4627659574468087e-05, Avg Loss : 0.2383\n",
            "Epoch: 1, Step : 30, LR : 1.4450354609929078e-05, Avg Loss : 0.2417\n",
            "Epoch: 1, Step : 40, LR : 1.427304964539007e-05, Avg Loss : 0.2517\n",
            "Epoch: 1, Step : 50, LR : 1.4095744680851065e-05, Avg Loss : 0.2501\n",
            "Epoch: 1, Step : 60, LR : 1.3918439716312057e-05, Avg Loss : 0.2425\n",
            "Epoch: 1, Step : 70, LR : 1.3741134751773051e-05, Avg Loss : 0.1670\n",
            "Epoch: 1, Step : 80, LR : 1.3563829787234044e-05, Avg Loss : 0.1896\n",
            "Epoch: 1, Step : 90, LR : 1.3386524822695038e-05, Avg Loss : 0.2474\n",
            "Epoch: 1, Step : 100, LR : 1.320921985815603e-05, Avg Loss : 0.1827\n",
            "Epoch: 1, Step : 110, LR : 1.3031914893617021e-05, Avg Loss : 0.2129\n",
            "Epoch: 1, Step : 120, LR : 1.2854609929078014e-05, Avg Loss : 0.2174\n",
            "Epoch: 1, Step : 130, LR : 1.2677304964539008e-05, Avg Loss : 0.2430\n",
            "Epoch: 1, Step : 140, LR : 1.25e-05, Avg Loss : 0.1503\n",
            "Epoch: 1, Step : 150, LR : 1.2322695035460995e-05, Avg Loss : 0.2277\n",
            "Epoch: 1, Step : 160, LR : 1.2145390070921987e-05, Avg Loss : 0.2509\n",
            "Epoch: 1, Step : 170, LR : 1.196808510638298e-05, Avg Loss : 0.2323\n",
            "Epoch: 1, Step : 180, LR : 1.1790780141843972e-05, Avg Loss : 0.2167\n",
            "Epoch: 1, Step : 190, LR : 1.1613475177304965e-05, Avg Loss : 0.2402\n",
            "Epoch: 1, Step : 200, LR : 1.1436170212765957e-05, Avg Loss : 0.2373\n",
            "Epoch: 1, Step : 210, LR : 1.1258865248226952e-05, Avg Loss : 0.2355\n",
            "Epoch: 1, Step : 220, LR : 1.1081560283687944e-05, Avg Loss : 0.2307\n",
            "Epoch: 1, Step : 230, LR : 1.0904255319148938e-05, Avg Loss : 0.2327\n",
            "Epoch: 1, Step : 240, LR : 1.072695035460993e-05, Avg Loss : 0.2444\n",
            "Epoch: 1, Step : 250, LR : 1.0549645390070923e-05, Avg Loss : 0.3008\n",
            "Epoch: 1, Step : 260, LR : 1.0372340425531916e-05, Avg Loss : 0.1943\n",
            "Epoch: 1, Step : 270, LR : 1.0195035460992908e-05, Avg Loss : 0.2240\n",
            "Epoch: 1, Step : 280, LR : 1.00177304964539e-05, Avg Loss : 0.1583\n",
            "Epoch 1 Total Mean Loss : 0.2239\n",
            "*****Epoch 1 Train Finish*****\n",
            "\n",
            "*****Epoch 1 Valid Start*****\n",
            "Epoch 1 Valid Loss : 0.3858 Valid Acc : 85.47\n",
            "*****Epoch 1 Valid Finish*****\n",
            "\n",
            "Saving epoch 1 checkpoint at ./model.ckpt.1\n",
            "*****Epoch 2 Train Start*****\n",
            "Epoch: 2, Step : 10, LR : 9.804964539007093e-06, Avg Loss : 0.1605\n",
            "Epoch: 2, Step : 20, LR : 9.627659574468086e-06, Avg Loss : 0.1446\n",
            "Epoch: 2, Step : 30, LR : 9.450354609929078e-06, Avg Loss : 0.1205\n",
            "Epoch: 2, Step : 40, LR : 9.273049645390073e-06, Avg Loss : 0.1236\n",
            "Epoch: 2, Step : 50, LR : 9.095744680851063e-06, Avg Loss : 0.1202\n",
            "Epoch: 2, Step : 60, LR : 8.918439716312058e-06, Avg Loss : 0.1148\n",
            "Epoch: 2, Step : 70, LR : 8.74113475177305e-06, Avg Loss : 0.1383\n",
            "Epoch: 2, Step : 80, LR : 8.563829787234044e-06, Avg Loss : 0.2233\n",
            "Epoch: 2, Step : 90, LR : 8.386524822695035e-06, Avg Loss : 0.0952\n",
            "Epoch: 2, Step : 100, LR : 8.20921985815603e-06, Avg Loss : 0.1119\n",
            "Epoch: 2, Step : 110, LR : 8.031914893617022e-06, Avg Loss : 0.1254\n",
            "Epoch: 2, Step : 120, LR : 7.854609929078016e-06, Avg Loss : 0.2031\n",
            "Epoch: 2, Step : 130, LR : 7.677304964539007e-06, Avg Loss : 0.1070\n",
            "Epoch: 2, Step : 140, LR : 7.500000000000001e-06, Avg Loss : 0.1148\n",
            "Epoch: 2, Step : 150, LR : 7.3226950354609935e-06, Avg Loss : 0.1396\n",
            "Epoch: 2, Step : 160, LR : 7.145390070921986e-06, Avg Loss : 0.1600\n",
            "Epoch: 2, Step : 170, LR : 6.968085106382979e-06, Avg Loss : 0.1416\n",
            "Epoch: 2, Step : 180, LR : 6.790780141843972e-06, Avg Loss : 0.1411\n",
            "Epoch: 2, Step : 190, LR : 6.613475177304965e-06, Avg Loss : 0.1830\n",
            "Epoch: 2, Step : 200, LR : 6.436170212765958e-06, Avg Loss : 0.1436\n",
            "Epoch: 2, Step : 210, LR : 6.258865248226951e-06, Avg Loss : 0.1030\n",
            "Epoch: 2, Step : 220, LR : 6.081560283687944e-06, Avg Loss : 0.1525\n",
            "Epoch: 2, Step : 230, LR : 5.904255319148937e-06, Avg Loss : 0.1442\n",
            "Epoch: 2, Step : 240, LR : 5.7269503546099295e-06, Avg Loss : 0.1457\n",
            "Epoch: 2, Step : 250, LR : 5.549645390070923e-06, Avg Loss : 0.1329\n",
            "Epoch: 2, Step : 260, LR : 5.372340425531915e-06, Avg Loss : 0.1488\n",
            "Epoch: 2, Step : 270, LR : 5.195035460992908e-06, Avg Loss : 0.2254\n",
            "Epoch: 2, Step : 280, LR : 5.017730496453901e-06, Avg Loss : 0.1726\n",
            "Epoch 2 Total Mean Loss : 0.1438\n",
            "*****Epoch 2 Train Finish*****\n",
            "\n",
            "*****Epoch 2 Valid Start*****\n",
            "Epoch 2 Valid Loss : 0.4165 Valid Acc : 85.92\n",
            "*****Epoch 2 Valid Finish*****\n",
            "\n",
            "Saving epoch 2 checkpoint at ./model.ckpt.2\n",
            "*****Epoch 3 Train Start*****\n",
            "Epoch: 3, Step : 10, LR : 4.804964539007093e-06, Avg Loss : 0.1080\n",
            "Epoch: 3, Step : 20, LR : 4.6276595744680855e-06, Avg Loss : 0.0552\n",
            "Epoch: 3, Step : 30, LR : 4.450354609929078e-06, Avg Loss : 0.1033\n",
            "Epoch: 3, Step : 40, LR : 4.273049645390071e-06, Avg Loss : 0.1145\n",
            "Epoch: 3, Step : 50, LR : 4.095744680851064e-06, Avg Loss : 0.0887\n",
            "Epoch: 3, Step : 60, LR : 3.918439716312057e-06, Avg Loss : 0.0942\n",
            "Epoch: 3, Step : 70, LR : 3.74113475177305e-06, Avg Loss : 0.1213\n",
            "Epoch: 3, Step : 80, LR : 3.5638297872340426e-06, Avg Loss : 0.0940\n",
            "Epoch: 3, Step : 90, LR : 3.386524822695036e-06, Avg Loss : 0.1096\n",
            "Epoch: 3, Step : 100, LR : 3.2092198581560285e-06, Avg Loss : 0.1110\n",
            "Epoch: 3, Step : 110, LR : 3.031914893617022e-06, Avg Loss : 0.0789\n",
            "Epoch: 3, Step : 120, LR : 2.8546099290780144e-06, Avg Loss : 0.1676\n",
            "Epoch: 3, Step : 130, LR : 2.6773049645390077e-06, Avg Loss : 0.0915\n",
            "Epoch: 3, Step : 140, LR : 2.5e-06, Avg Loss : 0.1461\n",
            "Epoch: 3, Step : 150, LR : 2.322695035460993e-06, Avg Loss : 0.0678\n",
            "Epoch: 3, Step : 160, LR : 2.145390070921986e-06, Avg Loss : 0.0843\n",
            "Epoch: 3, Step : 170, LR : 1.968085106382979e-06, Avg Loss : 0.0818\n",
            "Epoch: 3, Step : 180, LR : 1.790780141843972e-06, Avg Loss : 0.1032\n",
            "Epoch: 3, Step : 190, LR : 1.6134751773049648e-06, Avg Loss : 0.0639\n",
            "Epoch: 3, Step : 200, LR : 1.4361702127659578e-06, Avg Loss : 0.0692\n",
            "Epoch: 3, Step : 210, LR : 1.2588652482269503e-06, Avg Loss : 0.1085\n",
            "Epoch: 3, Step : 220, LR : 1.0815602836879434e-06, Avg Loss : 0.0663\n",
            "Epoch: 3, Step : 230, LR : 9.042553191489363e-07, Avg Loss : 0.0906\n",
            "Epoch: 3, Step : 240, LR : 7.26950354609929e-07, Avg Loss : 0.1035\n",
            "Epoch: 3, Step : 250, LR : 5.496453900709221e-07, Avg Loss : 0.0959\n",
            "Epoch: 3, Step : 260, LR : 3.723404255319149e-07, Avg Loss : 0.0829\n",
            "Epoch: 3, Step : 270, LR : 1.9503546099290782e-07, Avg Loss : 0.0617\n",
            "Epoch: 3, Step : 280, LR : 1.773049645390071e-08, Avg Loss : 0.0759\n",
            "Epoch 3 Total Mean Loss : 0.0941\n",
            "*****Epoch 3 Train Finish*****\n",
            "\n",
            "*****Epoch 3 Valid Start*****\n",
            "Epoch 3 Valid Loss : 0.4970 Valid Acc : 85.82\n",
            "*****Epoch 3 Valid Finish*****\n",
            "\n",
            "Saving epoch 3 checkpoint at ./model.ckpt.3\n",
            "Train Completed. End Program.\n"
          ]
        }
      ],
      "source": [
        "epochs=4\n",
        "model, optimizer, scheduler = initializer(train_dataloader, epochs)\n",
        "train(model, train_dataloader, valid_dataloader, epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-02T03:27:18.246441Z",
          "start_time": "2022-02-02T03:27:18.236617Z"
        },
        "id": "vA3_vqqCXccc"
      },
      "source": [
        "### 가장 dev acc 성능이 높았던 epoch의 모델의 체크 포인트를 불러와 로드하자"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-02T06:22:27.646150Z",
          "start_time": "2022-02-02T06:22:26.945572Z"
        },
        "id": "XxO61K5eaMez"
      },
      "outputs": [],
      "source": [
        "checkpoint = torch.load('model.ckpt.2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-02T06:22:36.415665Z",
          "start_time": "2022-02-02T06:22:36.407250Z"
        },
        "id": "4mZuAKD-aMez",
        "outputId": "1c6ea42b-cc28-440c-e35d-fc42b3024768"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['epoch', 'model_state_dict', 'optimizer_state_dict', 'scheduler_state_dict', 'loss'])"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "checkpoint.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-02T06:22:40.272939Z",
          "start_time": "2022-02-02T06:22:37.010491Z"
        },
        "id": "0_aa2v4IaMez",
        "outputId": "af3bae18-ee96-471f-d0b7-b27dca3ce9d0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total train steps with 1 epochs: 282\n"
          ]
        }
      ],
      "source": [
        "epochs=1\n",
        "model, optimizer, scheduler = initializer(train_dataloader, epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-02T06:22:40.443912Z",
          "start_time": "2022-02-02T06:22:40.274323Z"
        },
        "id": "qLkEzX8laMe0",
        "outputId": "f46b6b25-6f70-46da-ed30-89ea722ebac2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.load_state_dict(checkpoint[\"model_state_dict\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KqjwDXl8aMe0"
      },
      "source": [
        "### 모델 예측 함수 구현\n",
        "- test_dataloader를 입력받아 모델이 예측한 확률값 (probs)과 실제 정답 (label) 을 출력하는 `\bpredict()` 함수를 구현하자.\n",
        "- 함수 정의\n",
        "  - 입력 매개변수\n",
        "    - `model` : `CustomClassifier` 모델. logits를 반환함 \n",
        "    - `test_dataloader` : test 데이터셋의 텍스트와 레이블을 배치로 갖는 dataloader\n",
        "  - 조건\n",
        "    - `test_dataloader`는 이터레이터기 때문에 이터레이터를 순회하면서 `all_logits` 리스트에 배치 단위의 logits를 저장하고 `all_labels` 리스트에 배치 단위의 레이블 (0 또는 1 값)을 저장하라\n",
        "  - 반환값\n",
        "    - `probs`\n",
        "      - logits에 softmax 함수를 취한 확률값. (test data 개수, label 개수) shape을 가짐. \bnp.array 타입으로 데이터 타입을 변환할 것.\n",
        "    - `labels`\n",
        "      - 0 또는 1 값을 갖는 np.array. (test data 개수,) shape을 가짐."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-02T06:22:48.062229Z",
          "start_time": "2022-02-02T06:22:48.057531Z"
        },
        "id": "yQ7WiD1Oigg9"
      },
      "outputs": [],
      "source": [
        "def predict(model, test_dataloader):\n",
        "    \"\"\"\n",
        "    test_dataloader의 label별 확률값과 실제 label 값을 반환\n",
        "    \"\"\"\n",
        "\n",
        "    model.eval()\n",
        "    model.to(device)\n",
        "\n",
        "    all_logits = []\n",
        "    all_labels = []\n",
        "\n",
        "    for step, batch in enumerate(test_dataloader):\n",
        "        print(f\"{step}/{len(test_dataloader)}\")\n",
        "        \n",
        "        batch_input, batch_label = batch\n",
        "        \n",
        "        batch_input = batch_input.to(device)\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            logits = model(**batch_input)\n",
        "            all_logits.append(logits)\n",
        "        all_labels.extend(batch_label)\n",
        "\n",
        "    all_logits = torch.cat(all_logits, dim=0)\n",
        "    probs = F.softmax(all_logits, dim=1).cpu().numpy()\n",
        "    all_labels = np.array(all_labels)\n",
        "\n",
        "    return probs, all_labels\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 모델이 예측한 확률값과 실제 label을 입력 받아 정확도를 출력하는 **accuracy()** 함수를 구현하자. \n",
        "- 함수 정의 \n",
        "  - 입력 매개변수 \n",
        "    - `probs` : `predict()` 함수의 반환값. 2차원의 np.array\n",
        "    - `labels` : `predict()` 함수의 반환값. 1차원의 np.array\n",
        "  - 조건\n",
        "    - `probs`의 확률값이 0.5 이상이면 1, 이하이면 0이 되도록 만든다. 모델이 예측한 레이블을 실제값(`labels`)과 비교해 예측값과 실제값이 같으면 1, 다르면 0 점수를 준다. 모든 데이터에 대해 점수의 평균값이 accuracy 값이다. \n",
        "  - 반환값 \n",
        "    - `acc` : 정확도 (Float type)"
      ],
      "metadata": {
        "id": "xeVEopukSA7T"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-02T06:22:48.296419Z",
          "start_time": "2022-02-02T06:22:48.293737Z"
        },
        "id": "nHC9SRKfaMe0"
      },
      "outputs": [],
      "source": [
        "def accuracy(probs, labels):\n",
        "    y_pred = np.where(probs>=0.5, 1, 0)\n",
        "    return float(sum(labels == np.argmax(y_pred, axis=1)) / len(labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-02T06:24:22.752497Z",
          "start_time": "2022-02-02T06:22:48.652784Z"
        },
        "id": "SwkrRPAhjsXb",
        "outputId": "e1ca64c3-9090-4466-9b7c-bdfa9efa90f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0/16\n",
            "1/16\n",
            "2/16\n",
            "3/16\n",
            "4/16\n",
            "5/16\n",
            "6/16\n",
            "7/16\n",
            "8/16\n",
            "9/16\n",
            "10/16\n",
            "11/16\n",
            "12/16\n",
            "13/16\n",
            "14/16\n",
            "15/16\n"
          ]
        }
      ],
      "source": [
        "probs, labels = predict(model, test_dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-02T06:24:22.759367Z",
          "start_time": "2022-02-02T06:24:22.753997Z"
        },
        "id": "UN1Yi9kmaMe0",
        "outputId": "cd92986c-5981-4b85-a46e-4c7eaf1de331"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.867"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "accuracy(probs, labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3GGCFaapaMe1"
      },
      "source": [
        "### `sklearn.metrics`의 `accuracy_score`, `roc_auc_score` 함수를 이용해 정확도와 auc를 계산하라"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-02T06:24:23.111879Z",
          "start_time": "2022-02-02T06:24:22.760568Z"
        },
        "id": "8Srq-RsgaMe1"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_auc_score, accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-02T06:24:23.116872Z",
          "start_time": "2022-02-02T06:24:23.113064Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p9BEe2mflTem",
        "outputId": "2f145ffe-9ac6-4230-960d-ee9adc98c47d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.867"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "accuracy_score(labels,  np.argmax(probs, axis=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-02T06:24:23.125650Z",
          "start_time": "2022-02-02T06:24:23.117847Z"
        },
        "id": "oCl6BiPGpCPW",
        "outputId": "ffa453da-1e68-4a91-e13f-1c54fb26077a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9380059999999999"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "roc_auc_score(labels, probs[:,1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FJKeh2CFaMe1"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Week2_4_assignment_ta.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "torch",
      "language": "python",
      "name": "torch"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.11"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0f906f35b2a04f2b9a98c5141b3500ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_447f75968c8b478ab8fe3b2cb4fd6951",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ad20c09fa31c484687cb4008575649c8",
              "IPY_MODEL_4849d465a2be4a95b03f5eaff782cc3f",
              "IPY_MODEL_5b8538f4a1f94796a77fd8b6042e5ae9"
            ]
          }
        },
        "447f75968c8b478ab8fe3b2cb4fd6951": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ad20c09fa31c484687cb4008575649c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_49f72347cc4d414e8a16ba04c4236029",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b23eaa8a9cba44328968f711af4a2943"
          }
        },
        "4849d465a2be4a95b03f5eaff782cc3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_70a4249ac876489fbaa4286bfe73e883",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 425,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 425,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_03c7552d696741fe992bce4b1bc9bb2a"
          }
        },
        "5b8538f4a1f94796a77fd8b6042e5ae9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7a65ad8c877846e8a6f206eeb2754e31",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 425/425 [00:00&lt;00:00, 12.2kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c4b1594093884ca5aabd96a386f81288"
          }
        },
        "49f72347cc4d414e8a16ba04c4236029": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b23eaa8a9cba44328968f711af4a2943": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "70a4249ac876489fbaa4286bfe73e883": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "03c7552d696741fe992bce4b1bc9bb2a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7a65ad8c877846e8a6f206eeb2754e31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c4b1594093884ca5aabd96a386f81288": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1e604284d92542b181aca9f164404b89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e2a022db622045c9b61a7ef909b0e5c3",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2442cef960ba45ddb52c03c00137a1b6",
              "IPY_MODEL_f7522ff585f2423593e9f9d9fb75d588",
              "IPY_MODEL_5bab9ea6663b4e8f8c028ca70d115064"
            ]
          }
        },
        "e2a022db622045c9b61a7ef909b0e5c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2442cef960ba45ddb52c03c00137a1b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3250d59be7fd446a96bad425216de4f7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1cabb1afb33546f4bdfda4116deeea4e"
          }
        },
        "f7522ff585f2423593e9f9d9fb75d588": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5fc05b5d176f4a4bb8ad0aa528ddc1f0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 445025130,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 445025130,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_15e1406373834500885b5db22f89b1d2"
          }
        },
        "5bab9ea6663b4e8f8c028ca70d115064": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9b2b03353e2b48698b8952bc2e7abe65",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 424M/424M [00:08&lt;00:00, 46.3MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c1b421531cba4e9e961f1fe8cfe4428c"
          }
        },
        "3250d59be7fd446a96bad425216de4f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1cabb1afb33546f4bdfda4116deeea4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5fc05b5d176f4a4bb8ad0aa528ddc1f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "15e1406373834500885b5db22f89b1d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9b2b03353e2b48698b8952bc2e7abe65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c1b421531cba4e9e961f1fe8cfe4428c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}